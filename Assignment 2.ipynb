{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f86925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33583c67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  (4600, 57)\n",
      "Size of y:  (4600,)\n",
      "Type of X:  word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "Type of y:  int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "from yellowbrick.datasets import load_spam\n",
    "X, y = load_spam()\n",
    "print(\"Size of X: \", X.shape)\n",
    "print(\"Size of y: \", y.shape)\n",
    "print(\"Type of X: \", X.dtypes)\n",
    "print(\"Type of y: \", y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7204f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X NaN:  0\n",
      "Y NaN:  0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"X NaN: \", X.isnull().sum().sum())\n",
    "print(\"Y NaN: \", y.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9bc4a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4370, 57)\n",
      "(230, 57)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This divides the data by 5% and creates a new target vector called X_small and y_small\n",
    "X_ex, X_small, y_ex, y_small = train_test_split(X, y, \n",
    "                                                    test_size=0.05,\n",
    "                                                    random_state=0)\n",
    "print(X_ex.shape)\n",
    "print(X_small.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be4b5c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Data Size  Training Accuracy  Validation Accuracy\n",
      "0  (4600, 57)           0.927717             0.921739\n",
      "1   (4600, 2)           0.615693             0.614402\n",
      "2   (230, 57)           0.956527             0.902102\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Now we do a train test split with a test size of 20% and train of 80% for 3 different databases:\n",
    "\n",
    "# X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "# first two columns of X and y\n",
    "X_col2_train, X_col2_test, y_col2_train, y_col2_test = train_test_split(X.iloc[:,:2], y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "# X_small and y_small\n",
    "X_small_train, X_small_test, y_small_train, y_small_test = train_test_split(X_small, y_small, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "# Apply the model\n",
    "model1 = model.fit(X_train, y_train) # X and y\n",
    "model2 = model.fit(X_col2_train, y_col2_train) # X and y first two columns\n",
    "model3 = model.fit(X_small_train, y_small_train) # X_small and y_small\n",
    "\n",
    "# Training and validation scores for each model\n",
    "scores1 = cross_validate(model1, X_train, y_train, cv=5, \n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "for label_pair in [ ('train_score', 'train_score')]:\n",
    "    train1 = (scores1[label_pair[0]].mean())\n",
    "for label_pair in [ ('test_score', 'validation_score')]:\n",
    "    val1 = (scores1[label_pair[0]].mean())\n",
    "    \n",
    "scores2 = cross_validate(model2, X_col2_train, y_col2_train, cv=5, \n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "for label_pair in [ ('train_score', 'train_score')]:\n",
    "    train2 = (scores2[label_pair[0]].mean())\n",
    "for label_pair in [ ('test_score', 'validation_score')]:\n",
    "    val2 = (scores2[label_pair[0]].mean())\n",
    "    \n",
    "scores3 = cross_validate(model3, X_small_train, y_small_train, cv=5, \n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "for label_pair in [ ('train_score', 'train_score')]:\n",
    "    train3 = (scores3[label_pair[0]].mean())\n",
    "for label_pair in [ ('test_score', 'validation_score')]:\n",
    "    val3 = (scores3[label_pair[0]].mean())\n",
    "    \n",
    "# Creating the Dataframe\n",
    "data = {'Data Size': [X.shape, X.iloc[:,:2].shape, X_small.shape],\n",
    "            'Training Accuracy': [train1, train2, train3],\n",
    "            'Validation Accuracy': [val1, val2, val3]}\n",
    "results = pd.DataFrame(data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "#### Answers\n",
    "1. The training and validation accuracy is the best for the entire dataset, with the most data, since both training and validation is similar at 92.8% and 92.2% at this point. When only the first two columns are used, both training and accuracy is terrible at 61.6% and 61.4% and the data is underfitted with high-bias. This might be because all columns are significant. For just 5% of the data, the training is very high at 95.6% but the testing is low at 90.2% indicating an overfitted data and a high-variance.\n",
    "\n",
    "2. In this case, a false positive might be that the email received is not spam but labelled as such and a false negative might be that the email is spam but not categorized. In this case, a false positive would be far worse, since you do not want important emails to be marked as spam, while spam emails are fine to ocassionally pop-up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. The source code was derived from the lecture example: Linear Example. All information originated from here.\n",
    "2. The steps were completed in the order they were asked.\n",
    "3. No generative AI was necessary since the lecture code was simple enough to easily modify without external resources.\n",
    "4. The only challenge faced was dividing the data into 5%, which was overcome with the help of the professor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  (1030, 8)\n",
      "Size of y:  (1030,)\n",
      "Type of X:  cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "Type of y:  float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()\n",
    "print(\"Size of X: \", X.shape)\n",
    "print(\"Size of y: \", y.shape)\n",
    "print(\"Type of X: \", X.dtypes)\n",
    "print(\"Type of y: \", y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X NaN:  0\n",
      "Y NaN:  0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"X NaN: \", X.isnull().sum().sum())\n",
    "print(\"Y NaN: \", y.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Now we do a train test split with a test size of 20% and train of 80% for the database:\n",
    "\n",
    "# X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Apply the model\n",
    "model = model.fit(X_train, y_train) # X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean squared error: 110.34550122934108\n",
      "Validation MSE: 95.63533482690428\n",
      "Training R2 Score: 0.6090710418548884\n",
      "Validation R2 Score: 0.6368981103411242\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "print(\"Training Mean squared error:\", mse_train)\n",
    "print(\"Validation MSE:\", mse_test)\n",
    "print(\"Training R2 Score:\", r2_train)\n",
    "print(\"Validation R2 Score:\", r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Training Accuracy  Validation Accuracy\n",
      "MSE              110.345501            95.635335\n",
      "R2 Score           0.609071             0.636898\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "# Creating the Dataframe\n",
    "data = {'Training Accuracy': [mse_train, r2_train],\n",
    "            'Validation Accuracy':[mse_test, r2_test]}\n",
    "\n",
    "results = pd.DataFrame(data, index=['MSE', 'R2 Score'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "Using the linear model did not produce good results since the mean squared error was very high, it should be close to 0. Also, the R2 score was very low and should have been closer to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. The source code was derived from the lecture example: Regression Metrics and Linear Regression. All information originated from here.\n",
    "2. The steps were completed in the order they were asked.\n",
    "3. Generative AI was used to get the mean squared error and R2 score. ChatGPT was asked \"Calculate the training and validation accuracy using mean squared error and R2 score\". The result was very close and only the variable names needed to be modified to fit the current code. Only a snipet of code was used from the code generated by ChatGPT.\n",
    "4. The only challenge faced was how exactly to get MSE and R2 score since there was no lecture example which went over these steps. ChatGPT was useful in helping generate this code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "For the R2 score, the validation accuracy was higher than the training (0.637 vs. 0.609) which should not happen according to the discussion. It should be close to each other but should never cross. The mean squared error for both testing and validation was very high (110.3 and 95.6). This error should be as low as possible to be a good fit, which it was not, meaning the model underfit the data. This means the data had a high bias and the model was too simple; we needed a more complex model to describe the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked how there were multiple datasets derived from the same data in part one that were used to compare results. This made it easier to grasp the concept about how the same data can be used in various ways to attain different results. The lab itself was simple to accomplish, since the code was given in lecture examples, making it very efficient to follow. The only challenge was dividing the data in the first part, since it required a bit of clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   MSE  R2 Score\n",
      "Training Accuracy: 0.001    110.345501  0.609071\n",
      "Validation Accuracy: 0.001   95.635335  0.636898\n",
      "Training Accuracy: 0.1      110.345501  0.609071\n",
      "Validation Accuracy: 0.1     95.635324  0.636898\n",
      "Training Accuracy: 1        110.345501  0.609071\n",
      "Validation Accuracy: 1       95.635231  0.636899\n",
      "Training Accuracy: 10       110.345502  0.609071\n",
      "Validation Accuracy: 10      95.634301  0.636902\n",
      "Training Accuracy: 100      110.345597  0.609071\n",
      "Validation Accuracy: 100     95.625173  0.636937\n",
      "Training Accuracy: 1000     110.353529  0.609043\n",
      "Validation Accuracy: 1000    95.548714  0.637227\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Ridge Alpha = 0.001\n",
    "ridge0001 = Ridge(alpha=0.001).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = ridge0001.predict(X_train)\n",
    "y_test_pred = ridge0001.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train0001 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test0001 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train0001 = r2_score(y_train, y_train_pred)\n",
    "r2_test0001 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Ridge Alpha = 0.1\n",
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = ridge01.predict(X_train)\n",
    "y_test_pred = ridge01.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train01 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test01 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train01 = r2_score(y_train, y_train_pred)\n",
    "r2_test01 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Ridge Alpha = 1\n",
    "ridge1 = Ridge().fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = ridge1.predict(X_train)\n",
    "y_test_pred = ridge1.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train1 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test1 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train1 = r2_score(y_train, y_train_pred)\n",
    "r2_test1 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Ridge Alpha = 10\n",
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = ridge10.predict(X_train)\n",
    "y_test_pred = ridge10.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train10 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test10 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train10 = r2_score(y_train, y_train_pred)\n",
    "r2_test10 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Ridge Alpha = 100\n",
    "ridge100 = Ridge(alpha=100).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = ridge100.predict(X_train)\n",
    "y_test_pred = ridge100.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train100 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test100 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train100 = r2_score(y_train, y_train_pred)\n",
    "r2_test100 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Ridge Alpha = 1000\n",
    "ridge1000 = Ridge(alpha=1000).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = ridge1000.predict(X_train)\n",
    "y_test_pred = ridge1000.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train1000 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test1000 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train1000 = r2_score(y_train, y_train_pred)\n",
    "r2_test1000 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "data = {'Training Accuracy: 0.001': [mse_train0001, r2_train0001],\n",
    "        'Validation Accuracy: 0.001':[mse_test0001, r2_test0001],\n",
    "        'Training Accuracy: 0.1': [mse_train01, r2_train01],\n",
    "        'Validation Accuracy: 0.1':[mse_test01, r2_test01],\n",
    "        'Training Accuracy: 1': [mse_train1, r2_train1],\n",
    "        'Validation Accuracy: 1':[mse_test1, r2_test1],\n",
    "        'Training Accuracy: 10': [mse_train10, r2_train10],\n",
    "        'Validation Accuracy: 10':[mse_test10, r2_test10],\n",
    "        'Training Accuracy: 100': [mse_train100, r2_train100],\n",
    "        'Validation Accuracy: 100':[mse_test100, r2_test100],\n",
    "        'Training Accuracy: 1000': [mse_train1000, r2_train1000],\n",
    "        'Validation Accuracy: 1000':[mse_test1000, r2_test1000]}\n",
    "\n",
    "results = pd.DataFrame(data, index=['MSE', 'R2 Score']).transpose().head(30)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50ec3c96-601e-4e91-9e10-a8bfffe73d90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   MSE  R2 Score\n",
      "Training Accuracy: 0.001    110.345501  0.609071\n",
      "Validation Accuracy: 0.001   95.634971  0.636899\n",
      "Training Accuracy: 0.1      110.346120  0.609069\n",
      "Validation Accuracy: 0.1     95.599545  0.637034\n",
      "Training Accuracy: 1        110.407340  0.608852\n",
      "Validation Accuracy: 1       95.335850  0.638035\n",
      "Training Accuracy: 10       112.093055  0.602880\n",
      "Validation Accuracy: 10      95.114791  0.638874\n",
      "Training Accuracy: 100      151.368492  0.463736\n",
      "Validation Accuracy: 100    126.142568  0.521070\n",
      "Training Accuracy: 1000     282.264844  0.000000\n",
      "Validation Accuracy: 1000   265.384493 -0.007594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# lasso Alpha = 0.001\n",
    "lasso0001 = Lasso(alpha=0.001, max_iter=100000).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = lasso0001.predict(X_train)\n",
    "y_test_pred = lasso0001.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train0001 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test0001 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train0001 = r2_score(y_train, y_train_pred)\n",
    "r2_test0001 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# lasso Alpha = 0.1\n",
    "lasso01 = Lasso(alpha=0.1, max_iter=100000).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = lasso01.predict(X_train)\n",
    "y_test_pred = lasso01.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train01 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test01 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train01 = r2_score(y_train, y_train_pred)\n",
    "r2_test01 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Lasso Alpha = 1\n",
    "lasso1 = Lasso(max_iter=100000).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = lasso1.predict(X_train)\n",
    "y_test_pred = lasso1.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train1 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test1 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train1 = r2_score(y_train, y_train_pred)\n",
    "r2_test1 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Lasso Alpha = 10\n",
    "lasso10 = Lasso(alpha=10, max_iter=100000).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = lasso10.predict(X_train)\n",
    "y_test_pred = lasso10.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train10 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test10 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train10 = r2_score(y_train, y_train_pred)\n",
    "r2_test10 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Lasso Alpha = 100\n",
    "lasso100 = Lasso(alpha=100, max_iter=100000).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = lasso100.predict(X_train)\n",
    "y_test_pred = lasso100.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train100 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test100 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train100 = r2_score(y_train, y_train_pred)\n",
    "r2_test100 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Lasso Alpha = 1000\n",
    "lasso1000 = Lasso(alpha=1000, max_iter=100000).fit(X_train, y_train)\n",
    "# Predictions for the training and testing sets for y\n",
    "y_train_pred = lasso1000.predict(X_train)\n",
    "y_test_pred = lasso1000.predict(X_test)\n",
    "# Calculate MSE for the training and testing sets\n",
    "mse_train1000 = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test1000 = mean_squared_error(y_test, y_test_pred)\n",
    "# Calculate R2 score for the training and testing sets\n",
    "r2_train1000 = r2_score(y_train, y_train_pred)\n",
    "r2_test1000 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "data = {'Training Accuracy: 0.001': [mse_train0001, r2_train0001],\n",
    "        'Validation Accuracy: 0.001':[mse_test0001, r2_test0001],\n",
    "        'Training Accuracy: 0.1': [mse_train01, r2_train01],\n",
    "        'Validation Accuracy: 0.1':[mse_test01, r2_test01],\n",
    "        'Training Accuracy: 1': [mse_train1, r2_train1],\n",
    "        'Validation Accuracy: 1':[mse_test1, r2_test1],\n",
    "        'Training Accuracy: 10': [mse_train10, r2_train10],\n",
    "        'Validation Accuracy: 10':[mse_test10, r2_test10],\n",
    "        'Training Accuracy: 100': [mse_train100, r2_train100],\n",
    "        'Validation Accuracy: 100':[mse_test100, r2_test100],\n",
    "        'Training Accuracy: 1000': [mse_train1000, r2_train1000],\n",
    "        'Validation Accuracy: 1000':[mse_test1000, r2_test1000]}\n",
    "\n",
    "results = pd.DataFrame(data, index=['MSE', 'R2 Score']).transpose().head(30)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "For Ridge Regression, when testing R2 score, they were all pretty similar. They were only slightly different for alpha of 100 and 1000. The best one was an alpha of 1000 with a training accuracy of 0.609043 and validation accuracy of 0.637227. This was only minutely better than the linear regression. The results were still very bad and did not describe the data properly. There was still a high bias and the model was too simple. For the Lasso Regression, the best R2 score belonged to alpha of 10. This had a training score of 0.602880 and validation score of 0.638874. The worst score was an alpha of 1000 with a score of 0 and negative. Lasso Regression had the best validation score out of all the models, but was still a poor score overall, since there was still a high bias and the model was still to simple for the dataset. As R2 score should be close to 1, the models did not come close to this score at all.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
